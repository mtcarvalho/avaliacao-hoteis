{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de avaliações de hotéis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este *notebook* visa demonstrar o passo-a-passo de uma análise de avaliações de hotéis, realizadas com o método de aprendizado supervisionado *Random Forest*, cujo objetivo é prever se uma determinada avaliação é positiva ou negativa. Para melhorar a acurácia das predições, utilizaremos alguns métodos de manipulação e contagem das palavras nas avaliações. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Observação inicial dos dados\n",
    "\n",
    "Primeiramente, vamos fazer uma breve análise dos dados. Para tal, é necessário utilizar a biblioteca *liac-arff*, que implementa funções para ler e gravar arquivos ARFF em Python, e a *pandas*, que é uma ferramenta para estrutura e análise de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: liac-arff in c:\\programdata\\anaconda3\\lib\\site-packages (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install liac-arff\n",
    "import arff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as bibliotecas carregadas, vamos importar o arquivo contendo os dados, e convertê-lo para tipo *Dataframe* da biblioteca *pandas*, a fim de ser melhor manipulado. Após, vamos definir os rótulos para as colunas do *Dataframe* - o *label* é a coluna *class*, que contém a informação se a avaliação é positiva ou negativa, e a coluna *text*, que é o texto da avaliação. Por fim, vamos visualizar os primeiros registros da base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vocês são o melhor</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foi muito grato trabalhar com voces</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realizei o aniversario de meu sobrinho na terc...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gostei muito do atendimento personalizado/n</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grande hotel com otimas acomodacoes, a beira d...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class\n",
       "0                                vocês são o melhor    pos\n",
       "1               foi muito grato trabalhar com voces    pos\n",
       "2  realizei o aniversario de meu sobrinho na terc...   pos\n",
       "3       gostei muito do atendimento personalizado/n    pos\n",
       "4  grande hotel com otimas acomodacoes, a beira d...   pos"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = arff.load(open('data/hoteis.arff', 'r'))\n",
    "data = pd.DataFrame(dataset['data'])\n",
    "data.columns = ['text', 'class'] \n",
    "\n",
    "data.head()                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, visualizamos a quantidade de (linhas, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem valores nulos (por coluna)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     False\n",
       "class    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de avaliações positivas e negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    207\n",
       "neg    204\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Separação dos dados\n",
    "\n",
    "Agora, vamos separar os dados em um grupo de treino e outro de teste, e para isso vamos utilizar a *sklearn.model_selection*, que compara, valida e escolhe parâmetros e modelos. Definimos uma variável X que contém os dados sem o *label*, cujo nome definimos como *class*. O parâmetro *axis=1* estabelece que a definição das colunas a serem excluídas será pelo nome da coluna. Na variável Y, são inseridos os dados da *class*. Com o método *train_test_spit*, separamos dados de treino e teste de forma aleatória, com tamanho do conjunto de teste sendo 20% do total da base, e com o atributo *random_state* definindo que a semente (pseudo-)aleatória é 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-16eff694ad59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;31m# For backward compatibility with v0.19.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\csgraph\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_laplacian\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlaplacian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_shortest_path\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshortest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloyd_warshall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdijkstra\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[0mbellman_ford\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjohnson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNegativeCycleError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_traversal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbreadth_first_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_first_order\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_shortest_path.pyx\u001b[0m in \u001b[0;36minit scipy.sparse.csgraph._shortest_path\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('class', axis=1).values \n",
    "y = data['class'].values\n",
    "\n",
    "train_features, test_features, class_train, class_test = train_test_split(X, y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. StopWords\n",
    "\n",
    "Vamos utilizar o pacote *stopwords*, presente na biblioteca *nltk* (que auxilia a construir programas para trabalhar com dados em linguagem humana), a fim de retirar das avaliações as *stop words* presentes nas frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "import nltk # \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CountVectorizer\n",
    "\n",
    "A biblioteca *sklearn* extrai recursos em um formato suportado por algoritmos de aprendizado de máquina a partir de conjuntos de dados. A classe *CountVectorizer* faz parte dessa biblioteca, e fornece uma maneira simples de tokenizar uma coleção de documentos de texto e construir um vocabulário de palavras conhecidas. Com ela, podemos criar uma matriz com a quantidade de vezes que cada palavra foi utilizada em cada frase.\n",
    "\n",
    "Na nossa análise, utilizaremos a *CountVectorizer* para os dados com e sem *stop words*.\n",
    "\n",
    "Abaixo, é criada a matriz com a contagem de cada token **sem** *stop words*. O método *fit_transform* da classe *CountVectorizer* processa os dados e retorna a matriz com tokens; *ravel* \"nivela\" os *arrays*. O método *transform* aplica o mesmo procedimento na base de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "cv_train_features = cv.fit_transform(train_features.ravel()) \n",
    "cv_test_features = cv.transform(test_features.ravel())\n",
    "\n",
    "print('Shape das features (linhas, colunas) SEM stop words de treino {0} e de teste {1}'.format(cv_train_features.shape, cv_test_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, a *CountVectorizer* é utilizada para contar os tokens **com** *stop words*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sw = CountVectorizer(stopwords.words('portuguese'))\n",
    "cv_sw_train_features = cv_sw.fit_transform(train_features.ravel()) \n",
    "cv_sw_test_features = cv_sw.transform(test_features.ravel())\n",
    "\n",
    "print('Shape das features (linhas, colunas) COM stop words de treino {0} e de teste {1}'.format(cv_sw_train_features.shape, cv_sw_test_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Funções Auxiliares\n",
    "\n",
    "Abaixo definimos algumas funções para facilitar o uso de modelos e demonstrar os resultados dos mesmos. É importado o módulo *sklearn*, que inclui métricas de desempenho e cálculos de distâncias e métricas de pares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "def train_predict_model(classifier, train_features, train_labels, test_features, test_labels):\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    predictions = classifier.predict(test_features) \n",
    "    return predictions \n",
    "\n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm, columns=pd.MultiIndex(levels=[['Predicted:'], classes], labels=level_labels), \n",
    "                            index=pd.MultiIndex(levels=[['Actual:'], classes], labels=level_labels)) \n",
    "    print(cm_frame) \n",
    "\n",
    "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
    "    report = metrics.classification_report(y_true=true_labels, y_pred=predicted_labels, labels=classes) \n",
    "    print(report)\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print('Accuracy:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 4))\n",
    "    print('Precision:', np.round(metrics.precision_score(true_labels, predicted_labels, average='weighted'), 4))\n",
    "    print('Recall:', np.round( metrics.recall_score(true_labels, predicted_labels, average='weighted'), 4))\n",
    "    print('F1 Score:', np.round(metrics.f1_score(true_labels, predicted_labels, average='weighted'), 4))\n",
    "    \n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n",
    "    print('Model Performance metrics:')\n",
    "    print('-'*30)\n",
    "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    print('\\nModel Classification report:')\n",
    "    print('-'*30)\n",
    "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, classes=classes)\n",
    "    print('\\nPrediction Confusion Matrix:')\n",
    "    print('-'*30)\n",
    "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Random Forest\n",
    "\n",
    "Por fim, vamos utilizar o modelo Random Forest, que é um algoritmo de aprendizagem supervisionada, que utiliza métodos de comitês. Ele cria árvores de decisão e as combina para obter uma predição com maior acurácia.\n",
    "\n",
    "Para tal, vamos utilizar a classe *RandomForestClassifier* com *n_jobs = -1*, que define que todos os processadores serão utilizados em paralelo para fazer o *fit* e prever. Essa classe faz parte da biblioteca *sklearn.ensemble*, que combina as predições de vários estimadores construídos com um dado algoritmo de aprendizado; e a *numpy*, que é uma das principais bibliotecas para computação científica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import numpy as np\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 RF com stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc, train_features=cv_sw_train_features, train_labels=class_train,\n",
    "                                            test_features=cv_sw_test_features, test_labels=class_test)\n",
    "\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions, classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 RF sem stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc, \n",
    "                                            train_features=cv_train_features, train_labels=class_train,\n",
    "                                            test_features=cv_test_features, test_labels=class_test)\n",
    "\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions,classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a execução do modelo com e sem *stop words*, podemos notar que a acurácia do modelo sem *stop words* é um pouco melhor do que o modelo com *stop words*, o que faz sentido, já que as *stop words* não tem significado positivo ou negativo, trazendo pouco impacto à predição da classificação da avaliação. Em uma base com um volume maior de dados, talvez a discrepância entre os valores fosse maior, fazendo jus à essa afirmação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. TF-IDF\n",
    "\n",
    "O TD-IDF de uma coleção de documentos é uma medida que indica a importância das palavras presentes nele em relação à coleção. Para calcular essa medida, vamos utilizar a classe *TfidfVectorizer* presente na biblioteca *sklearn*. Os valores de *min_df* e *max_df* em seu construtor estabelecem que nenhuma palavra será ignorada, *sublinear_tf* diminui o \"bias\", e *ngram_range* define se serão gerados apenas *unigrams*, *bigrams*, e etc. Nessa análise, vamos realizar uma abordagem com *unigrams*, *unigrams e bigrams*, e *unigrams, bigrams e trigrams*, a fim de verificar qual tem a melhor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 TF-IDF com unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_unigrams = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,1), sublinear_tf=True) \n",
    "tv_train_features = tv_unigrams.fit_transform(train_features.ravel())\n",
    "tv_test_features = tv_unigrams.transform(test_features.ravel())\n",
    "\n",
    "print('Shape das features (linhas, colunas) de treino {0} e de teste {1}'.format(tv_train_features.shape, tv_test_features.shape))\n",
    "\n",
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc, train_features=tv_train_features, train_labels=class_train,\n",
    "                                            test_features=tv_test_features, test_labels=class_test)\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions,classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 TF-IDF com unigrams e bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_unigrams = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n",
    "tv_train_features = tv_unigrams.fit_transform(train_features.ravel())\n",
    "tv_test_features = tv_unigrams.transform(test_features.ravel())\n",
    "\n",
    "print('Shape das features (linhas, colunas) de treino {0} e de teste {1}'.format(tv_train_features.shape, tv_test_features.shape))\n",
    "\n",
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc, train_features=tv_train_features, train_labels=class_train,\n",
    "                                            test_features=tv_test_features, test_labels=class_test)\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions,classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 TF-IDF com unigrams, bigrams e trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_unigrams = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,3), sublinear_tf=True)\n",
    "tv_train_features = tv_unigrams.fit_transform(train_features.ravel())\n",
    "tv_test_features = tv_unigrams.transform(test_features.ravel())\n",
    "\n",
    "print('Shape das features (linhas, colunas) de treino {0} e de teste {1}'.format(tv_train_features.shape, tv_test_features.shape))\n",
    "\n",
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc, train_features=tv_train_features, train_labels=class_train,\n",
    "                                            test_features=tv_test_features, test_labels=class_test)\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions,classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia com *TF-IDF* é um pouco menor do que com *CountVectorizer*. Além disso, podemos notar que quanto mais *n-grams* adicionamos, pior fica a acurácia. Com isso, o modelo com apenas *unigrams* é o mais indicado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Stemmer\n",
    "\n",
    "É um processo automatizado que retorna uma *string* de base, dada uma determinada *string*, a fim de encontrar palavras relacionadas, com mesma base. Para tal, vamos utilizar o pacote *rslp*, que é um removedor de sufixos da língua portuguesa, presente na biblioteca *nltk*. A classe *RSLPStemmer* presente nele é responsável por isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('rslp') \n",
    "stemmer = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, vamos separar os *labels*, e após isso vamos remover o sufixo de cada palavra presente nas avaliações, para enfim separar os dados em treino e teste para verificar a performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['class'].values\n",
    "\n",
    "corpus = []\n",
    "for review in data['text']:\n",
    "    phrase = []\n",
    "    for word in review.split():\n",
    "        w_stemmed = stemmer.stem(word)\n",
    "        phrase.append(w_stemmed)\n",
    "    corpus.append(phrase)\n",
    "    \n",
    "train_features, test_features, class_train, class_test = train_test_split(corpus, y, test_size=0.20, random_state=10)\n",
    "\n",
    "rfc_stem_predictions = train_predict_model(classifier=rfc, \n",
    "                                           train_features=tv_train_features, train_labels=class_train,\n",
    "                                           test_features=tv_test_features, test_labels=class_test)\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_stem_predictions, classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurária utilizando *stemmer* é menor do que utilizando *TF-IDF* e *CountVectorizer*, talvez por conta da complexidade da língua portuguesa, esse método tenha obtido esse resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Separação de palavras em avaliações positivas e negativas\n",
    "\n",
    "Agora, vamos realizar a separação de palavras presentes em avaliações negativas e positivas, removendo as *stop words*, para plotá-las em uma *word cloud*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Separação de palavras em avaliações negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_phrases = data[data['class'] == 'neg']\n",
    "\n",
    "neg_string = []\n",
    "for phrase in neg_phrases['text']: \n",
    "    for word in phrase.split():\n",
    "        if word not in stopwords.words('portuguese'):\n",
    "            neg_string.append(word)\n",
    "\n",
    "neg_text = pd.Series(neg_string).str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Separação de palavras em avaliações positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_phrases = data[data['class'] == 'pos']\n",
    "pos_string = []\n",
    "for phrase in pos_phrases['text']:\n",
    "    for word in phrase.split():\n",
    "        if word not in stopwords.words('portuguese'):\n",
    "            pos_string.append(word)\n",
    "\n",
    "pos_text = pd.Series(pos_string).str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. WordCloud\n",
    "\n",
    "Com as palavras presentes em avaliações positivas e negativas, podemos plotá-las em uma *word cloud*, a fim de verificar as palavras que são mais utilizadas em cada tipo de avaliação. Para isso, vamos utilizar a biblioteca *wordcloud*, que gera *word clouds*, e o *framework matplotlib*, que plota dados da mesma forma que o *matlab*. Os parâmetros passados para os métodos das bibliotecas são para renderizar melhor a *word cloud*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1 Word Cloud de avaliações com palavras negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(neg_text)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 Word Cloud de avaliações com palavras positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(pos_text)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Créditos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outros projetos que acrescentaram - e muito - em conhecimento para realizar essa análise.\n",
    "\n",
    "[Intro to Movie Review Sentiment Analysis](https://www.kaggle.com/divsinha/sentiment-analysis-countvectorizer-tf-idf)\n",
    "[Horse Colic : life or death](https://www.kaggle.com/surya635/horse-colic-life-or-death) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
